{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_29444\\950706412.py:6: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import librosa\n","import os\n","import IPython.display as ipd\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.metrics import precision_score, recall_score\n","from torch.utils.data import DataLoader, Dataset\n","\n","import torch\n","from torcheval.metrics import MulticlassF1Score\n","from torchsummary import summary\n"]},{"cell_type":"raw","metadata":{},"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["B0.npy\n","B1.npy\n","C0.npy\n","C1.npy\n","Chash0.npy\n","Chash1.npy\n","D0.npy\n","D1.npy\n","Dhash0.npy\n","Dhash1.npy\n","E0.npy\n","E1.npy\n"]}],"source":["a = []\n","os.chdir(r\"D:\\\\UGP\\\\Mridangam_spectrograms\\\\Xnoisy\")\n","# names = [\"B0.npy\", \"C0.npy\", \"C#0.npy\", \"D0.npy\", \"D#0.npy\", \"E0.npy\"]\n","names = os.listdir()\n","for name in names:\n","    print(name)\n","    a.append(torch.Tensor(np.load(r\"D:\\\\UGP\\\\Mridangam_spectrograms\\\\Xnoisy\\\\\"+name)))\n","    \n","a = torch.cat(a, axis=0)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["B0.npy\n","B1.npy\n","C0.npy\n","C1.npy\n","Chash0.npy\n","Chash1.npy\n","D0.npy\n","D1.npy\n","Dhash0.npy\n","Dhash1.npy\n","E0.npy\n","E1.npy\n"]}],"source":["b = []\n","\n","for name in names:\n","    print(name)\n","    l = []\n","    t1 = np.load(r\"D:\\\\UGP\\\\Mridangam_spectrograms\\\\Y0\\\\\"+name)\n","    for ele in t1:\n","        l.append(torch.unsqueeze(torch.Tensor(ele.T), 0))\n","    l = torch.cat(l, axis=0)\n","    b.append(l)\n","    del(l)\n","    del(t1)\n","\n","# for name in names:\n","#   print(name)\n","#   b.append(np.load(\"/content/drive/MyDrive/UGP/Y/\"+name))\n","b = torch.cat(b, axis = 0)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    a = a.cuda()\n","    b = b.cuda()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1200, 1723, 11])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["b.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["b = b[:, :, [10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1200, 1723, 11])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["b.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["\n","epochs = 50\n","num_classes = 11\n","batch_size = 64\n","rnn_sizes = [16]\n","dropout_rate = 0.5\n","\n","\n","\n","class MyModel(nn.Module):\n","    def __init__(self, num_classes, rnn_sizes, dropout_rate):\n","        super(MyModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding='same')\n","        self.batch_norm1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding='same')\n","        self.batch_norm2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding='same')\n","        self.batch_norm3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3, 3), padding='same')\n","        self.batch_norm4 = nn.BatchNorm2d(256)\n","\n","        rnn_layers = []\n","        input_size = 2048  # Update the input size based on the shape after pooling\n","        for rnn_size in rnn_sizes:\n","            rnn_layers.append(nn.GRU(input_size, rnn_size, bidirectional=True, batch_first = True))\n","            input_size = rnn_size * 2\n","\n","        self.rnn_layers = nn.ModuleList(rnn_layers)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.dense = nn.Linear(input_size, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.batch_norm1(self.conv1(x)))\n","        x = F.max_pool2d(x, kernel_size=(2, 1))\n","        x = F.relu(self.batch_norm2(self.conv2(x)))\n","        x = F.max_pool2d(x, kernel_size=(2, 1))\n","        x = F.relu(self.batch_norm3(self.conv3(x)))\n","        x = F.max_pool2d(x, kernel_size=(2, 1))\n","        \n","        x = F.relu(self.batch_norm4(self.conv4(x)))\n","        x = F.max_pool2d(x, kernel_size=(2, 1))\n","        \n","        \n","        x = x.permute(0, 3, 2, 1)\n","        x = x.reshape(x.shape[0], x.shape[1], x.shape[2] * x.shape[3])\n","\n","        for rnn_layer in self.rnn_layers:\n","            x, _ = rnn_layer(x)\n","\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = F.softmax(x, dim = -1)\n","\n","        return x\n","\n","\n","\n","model = MyModel(num_classes, rnn_sizes, dropout_rate)\n","if torch.cuda.is_available():\n","    model = model.cuda()\n"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1        [-1, 32, 128, 1723]             320\n","       BatchNorm2d-2        [-1, 32, 128, 1723]              64\n","            Conv2d-3         [-1, 64, 64, 1723]          18,496\n","       BatchNorm2d-4         [-1, 64, 64, 1723]             128\n","            Conv2d-5        [-1, 128, 32, 1723]          73,856\n","       BatchNorm2d-6        [-1, 128, 32, 1723]             256\n","            Conv2d-7        [-1, 256, 16, 1723]         295,168\n","       BatchNorm2d-8        [-1, 256, 16, 1723]             512\n","               GRU-9  [[-1, 1723, 32], [-1, 2, 16]]               0\n","          Dropout-10             [-1, 1723, 32]               0\n","           Linear-11             [-1, 1723, 11]             363\n","================================================================\n","Total params: 389,163\n","Trainable params: 389,163\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.84\n","Forward/backward pass size (MB): 417.85\n","Params size (MB): 1.48\n","Estimated Total Size (MB): 420.18\n","----------------------------------------------------------------\n"]}],"source":["summary(model, input_size=(1, 128, 1723), batch_size = -1)"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([1200, 128, 1723]), torch.Size([1200, 1723, 11]))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["a.shape, b.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["# model(torch.unsqueeze(a[:10], dim = 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# torch.unsqueeze(a[:10], dim = 0)"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["arr = np.arange(1200)\n","np.random.shuffle(arr)\n","A, B = a[arr], b[arr]\n","del(a)\n","del(b)"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["\n","class MyDataset(Dataset):\n","    def __init__(self, inputs, targets):\n","        self.inputs = inputs\n","        self.targets = targets\n","        if torch.cuda.is_available():\n","            self.inputs = self.inputs.cuda()\n","            self.targets.cuda()\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, idx):\n","        return self.inputs[idx], self.targets[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# torch.sum(np.transpose(B[0])[0])"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.5158672  0.11517218 0.05173147 0.0630296  0.06814954 0.02295657\n"," 0.02122993 0.0232013  0.04438286 0.02442591 0.04985345] 2067600.0\n"]}],"source":["weights, total = [], 0\n","B = B.to(\"cpu\")\n","for num in range(11):\n","    tot = 0\n","    for i in B:\n","        tot += torch.sum(np.transpose(i)[num])\n","    total += tot\n","    weights.append(tot)\n","weights, total = np.array(weights), np.array([total])[0]\n","weights = weights/total\n","print(weights, total)"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["A = A/80 + 1"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[],"source":["# def load_checkpoint(filepath):\n","#     checkpoint = torch.load(filepath)\n","#     model = MyModel(num_classes, rnn_sizes, dropout_rate)\n","#     model.load_state_dict(checkpoint)\n","    \n","#     return model\n","\n","# new_model = load_checkpoint(\"/kaggle/input/saved-model/checkpoint0 (1).pth\")\n","# new_model = new_model.to(\"cuda\")"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[],"source":["# new_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":34,"metadata":{"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch number : 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[34], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch number : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m     epoch_loss, f_score\u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f_score = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[34], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m# Update statistics\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#         print(outputs.shape)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#         print(targets.shape)\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\adith\\OneDrive\\Desktop\\textbooks\\sem7\\Refactor\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\adith\\OneDrive\\Desktop\\textbooks\\sem7\\Refactor\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Define the training loop\n","def train(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss, bno = 0.0, 0\n","    metric = MulticlassF1Score(num_classes=11)\n","    for inputs, targets in train_loader:\n","        bno += 1\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        optimizer.zero_grad()\n","#         print(inputs.shape)\n","        # Forward pass\n","        outputs = model(torch.unsqueeze(inputs, dim = 1))\n","        # Calculate loss\n","        loss = criterion(outputs, targets)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Update statistics\n","#         print(outputs.shape)\n","#         print(targets.shape)\n","        running_loss += loss.item() * inputs.size(0)\n","        \n","#         x, y = torch.reshape(outputs, (outputs.shape[0]*outputs.shape[1], outputs.shape[2])), torch.reshape(torch.argmax(targets, axis = -1), (targets.shape[0]*targets.shape[1],))\n","\n","        metric.update(torch.reshape(outputs, (outputs.shape[0]*outputs.shape[1], outputs.shape[2])).to(\"cpu\"), torch.reshape(torch.argmax(targets, axis = -1), (targets.shape[0]*targets.shape[1],)).to(\"cpu\") )\n","        # _, predicted = torch.max(outputs.data, 1)\n","        # total_predictions += targets.size(0)\n","        # print(outputs.shape, targets.shape)\n","        # true_predictions += (predicted == targets).sum().item()\n","        \n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    # epoch_precision = true_predictions / total_predictions\n","    # epoch_recall = true_predictions / len(train_loader.dataset)\n","\n","    # return epoch_loss, epoch_precision, epoch_recall\n","    return epoch_loss, metric.compute()\n","\n","\n","# Example usage\n","# Set the device (GPU if available, else CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define the hyperparameters\n","epochs = 50\n","batch_size = 16\n","learning_rate = 0.002\n","\n","# Create the model instance\n","model = MyModel(num_classes, rnn_sizes, dropout_rate).to(device)\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Create the DataLoader for training dataset\n","train_dataset = MyDataset(A[:int(0.9*1200)], B[:int(0.9*1200)])\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Training loop\n","for epoch in range(epochs):\n","    print(f\"epoch number : {epoch + 1}\")\n","    epoch_loss, f_score= train(model, train_loader, criterion, optimizer, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, f_score = {f_score} \")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["import seaborn as sns\n","num = 100\n","sns.heatmap(new_model(torch.unsqueeze(A[num:num+1], dim = 1)).to(\"cpu\").detach().numpy()[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '/kaggle/working/checkpoint0.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
